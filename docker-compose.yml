version: "3"
services:

  ollama:
    image: ollama/ollama
    container_name: ollama
    volumes:
      - /home/ollama:/root/.ollama:z
    restart: unless-stopped
    ports:
      - 11434:11434
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
    networks:
      - chat_go_net

  chatsupportagent:
    container_name: chatsupportagent
    build:
      context: ./target
      dockerfile: ./Dockerfile
    image: chatsupportagent:latest
    ports:
      - "8185:8185"
    environment:
      OLLAMA_HOST: http://ollama:11434
      MODEL_NAME: llama3:8b
      JAR_NAME: ChatSupportAgent-0.0.1-SNAPSHOT.jar
    restart: always
    networks:
      - chat_go_net


networks:
  chat_go_net:
    external: true
    driver: bridge
